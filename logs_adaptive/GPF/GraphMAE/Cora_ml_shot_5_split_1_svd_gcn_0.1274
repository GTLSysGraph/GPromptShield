load LLC or attacked shot data with default split
{'scenario': 'poisoning', 'split': 0, 'adaptive_attack_model': 'svd_gcn', 'ptb_rate': 0.1274}
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7

Data(x=[2485, 1433], edge_index=[2, 13915], y=[2485], train_mask=[2485], val_mask=[2485], test_mask=[2485])
===========================================================================================================
Number of nodes: 2485
Number of edges: 13915
Average node degree: 5.60
Has isolated nodes: False
Has self-loops: True
Is undirected: True
None
tensor([1756,  307,   33, 1404,  188, 2052,  775,  774, 2081, 1717, 2068,  689,
         254, 1280,  225,  870, 2131, 1445, 1204, 1459, 1394, 1120,  728, 1165,
        1540, 2302, 1798,  937, 1929, 1764, 1142, 2143, 1830,  532,  803])
tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4,
        4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6])
len train nodes: 35
len val   nodes: 245
len test  nodes: 2205
Successfully loaded pre-trained weights!
prepare induce graph data is finished!
run GPF
Epoch 001 |  Time(s) 0.9172 | GPF Loss 1.9459  
Epoch 002 |  Time(s) 0.0387 | GPF Loss 1.9433  
Epoch 003 |  Time(s) 0.0361 | GPF Loss 1.9402  
Epoch 004 |  Time(s) 0.0355 | GPF Loss 1.9367  
Epoch 005 |  Time(s) 0.0361 | GPF Loss 1.9333  
Epoch 006 |  Time(s) 0.0348 | GPF Loss 1.9292  
Epoch 007 |  Time(s) 0.0373 | GPF Loss 1.9243  
Epoch 008 |  Time(s) 0.0350 | GPF Loss 1.9195  
Epoch 009 |  Time(s) 0.0351 | GPF Loss 1.9144  
Epoch 010 |  Time(s) 0.0383 | GPF Loss 1.9086  
Epoch 011 |  Time(s) 0.0373 | GPF Loss 1.9034  
Epoch 012 |  Time(s) 0.0372 | GPF Loss 1.8977  
Epoch 013 |  Time(s) 0.0368 | GPF Loss 1.8920  
Epoch 014 |  Time(s) 0.0364 | GPF Loss 1.8859  
Epoch 015 |  Time(s) 0.0367 | GPF Loss 1.8802  
Epoch 016 |  Time(s) 0.0367 | GPF Loss 1.8740  
Epoch 017 |  Time(s) 0.0365 | GPF Loss 1.8692  
Epoch 018 |  Time(s) 0.0365 | GPF Loss 1.8663  
Epoch 019 |  Time(s) 0.0364 | GPF Loss 1.8567  
Epoch 020 |  Time(s) 0.0366 | GPF Loss 1.8588  
Epoch 021 |  Time(s) 0.0379 | GPF Loss 1.8512  
Epoch 022 |  Time(s) 0.0357 | GPF Loss 1.8454  
Epoch 023 |  Time(s) 0.0355 | GPF Loss 1.8393  
Epoch 024 |  Time(s) 0.0356 | GPF Loss 1.8369  
Epoch 025 |  Time(s) 0.0337 | GPF Loss 1.8328  
Epoch 026 |  Time(s) 0.0346 | GPF Loss 1.8262  
Epoch 027 |  Time(s) 0.0339 | GPF Loss 1.8248  
Epoch 028 |  Time(s) 0.0342 | GPF Loss 1.8160  
Epoch 029 |  Time(s) 0.0339 | GPF Loss 1.8184  
Epoch 030 |  Time(s) 0.0367 | GPF Loss 1.8069  
Epoch 031 |  Time(s) 0.0350 | GPF Loss 1.8071  
Epoch 032 |  Time(s) 0.0348 | GPF Loss 1.8010  
Epoch 033 |  Time(s) 0.0343 | GPF Loss 1.7965  
Epoch 034 |  Time(s) 0.0348 | GPF Loss 1.7934  
Epoch 035 |  Time(s) 0.0440 | GPF Loss 1.7873  
Epoch 036 |  Time(s) 0.0349 | GPF Loss 1.7853  
Epoch 037 |  Time(s) 0.0350 | GPF Loss 1.7793  
Epoch 038 |  Time(s) 0.0344 | GPF Loss 1.7776  
Epoch 039 |  Time(s) 0.0383 | GPF Loss 1.7719  
Epoch 040 |  Time(s) 0.0420 | GPF Loss 1.7686  
Epoch 041 |  Time(s) 0.0359 | GPF Loss 1.7628  
Epoch 042 |  Time(s) 0.0343 | GPF Loss 1.7607  
Epoch 043 |  Time(s) 0.0337 | GPF Loss 1.7554  
Epoch 044 |  Time(s) 0.0337 | GPF Loss 1.7547  
Epoch 045 |  Time(s) 0.0362 | GPF Loss 1.7529  
Epoch 046 |  Time(s) 0.0340 | GPF Loss 1.7535  
Epoch 047 |  Time(s) 0.0345 | GPF Loss 1.7426  
Epoch 048 |  Time(s) 0.0361 | GPF Loss 1.7421  
Epoch 049 |  Time(s) 0.0344 | GPF Loss 1.7354  
Epoch 050 |  Time(s) 0.0342 | GPF Loss 1.7382  
Epoch 051 |  Time(s) 0.0356 | GPF Loss 1.7304  
Epoch 052 |  Time(s) 0.0394 | GPF Loss 1.7356  
Epoch 053 |  Time(s) 0.0369 | GPF Loss 1.7270  
Epoch 054 |  Time(s) 0.0351 | GPF Loss 1.7347  
Epoch 055 |  Time(s) 0.0457 | GPF Loss 1.7212  
Epoch 056 |  Time(s) 0.0359 | GPF Loss 1.7172  
Epoch 057 |  Time(s) 0.0352 | GPF Loss 1.7124  
Epoch 058 |  Time(s) 0.0343 | GPF Loss 1.7118  
Epoch 059 |  Time(s) 0.0388 | GPF Loss 1.7123  
Epoch 060 |  Time(s) 0.0340 | GPF Loss 1.7013  
Epoch 061 |  Time(s) 0.0334 | GPF Loss 1.7059  
Epoch 062 |  Time(s) 0.0337 | GPF Loss 1.6970  
Epoch 063 |  Time(s) 0.0340 | GPF Loss 1.6979  
Epoch 064 |  Time(s) 0.0375 | GPF Loss 1.6929  
Epoch 065 |  Time(s) 0.0348 | GPF Loss 1.6881  
Epoch 066 |  Time(s) 0.0318 | GPF Loss 1.6888  
Epoch 067 |  Time(s) 0.0402 | GPF Loss 1.6862  
Epoch 068 |  Time(s) 0.0345 | GPF Loss 1.6862  
Epoch 069 |  Time(s) 0.0320 | GPF Loss 1.6814  
Epoch 070 |  Time(s) 0.0486 | GPF Loss 1.6792  
Epoch 071 |  Time(s) 0.0363 | GPF Loss 1.6803  
Epoch 072 |  Time(s) 0.0306 | GPF Loss 1.6807  
Epoch 073 |  Time(s) 0.0383 | GPF Loss 1.6761  
Epoch 074 |  Time(s) 0.0350 | GPF Loss 1.6677  
Epoch 075 |  Time(s) 0.0358 | GPF Loss 1.6714  
Epoch 076 |  Time(s) 0.0366 | GPF Loss 1.6699  
Epoch 077 |  Time(s) 0.0358 | GPF Loss 1.6638  
Epoch 078 |  Time(s) 0.0367 | GPF Loss 1.6650  
Epoch 079 |  Time(s) 0.1738 | GPF Loss 1.6665  
Epoch 080 |  Time(s) 0.0758 | GPF Loss 1.6574  
Epoch 081 |  Time(s) 0.0314 | GPF Loss 1.6595  
Epoch 082 |  Time(s) 0.0322 | GPF Loss 1.6615  
Epoch 083 |  Time(s) 0.0317 | GPF Loss 1.6533  
Epoch 084 |  Time(s) 0.0320 | GPF Loss 1.6664  
Epoch 085 |  Time(s) 0.0893 | GPF Loss 1.6643  
Epoch 086 |  Time(s) 0.0317 | GPF Loss 1.6535  
Epoch 087 |  Time(s) 0.0309 | GPF Loss 1.6647  
Epoch 088 |  Time(s) 0.0605 | GPF Loss 1.6495  
Epoch 089 |  Time(s) 0.0331 | GPF Loss 1.6628  
Epoch 090 |  Time(s) 0.0349 | GPF Loss 1.6558  
Epoch 091 |  Time(s) 0.0483 | GPF Loss 1.6643  
Epoch 092 |  Time(s) 0.0316 | GPF Loss 1.6578  
Epoch 093 |  Time(s) 0.0311 | GPF Loss 1.6519  
Epoch 094 |  Time(s) 0.0308 | GPF Loss 1.6610  
Epoch 095 |  Time(s) 0.0302 | GPF Loss 1.6705  
Epoch 096 |  Time(s) 0.0784 | GPF Loss 1.6482  
Epoch 097 |  Time(s) 0.0314 | GPF Loss 1.6663  
Epoch 098 |  Time(s) 0.0323 | GPF Loss 1.6600  
Epoch 099 |  Time(s) 0.0519 | GPF Loss 1.6524  
Epoch 100 |  Time(s) 0.0308 | GPF Loss 1.6677  
Batch 0/23 Acc: 0.4300 | Macro-F1: 0.4216
Batch 1/23 Acc: 0.4800 | Macro-F1: 0.3803
Batch 2/23 Acc: 0.5700 | Macro-F1: 0.4710
Batch 3/23 Acc: 0.5300 | Macro-F1: 0.4796
Batch 4/23 Acc: 0.6700 | Macro-F1: 0.5591
Batch 5/23 Acc: 0.5100 | Macro-F1: 0.3332
Batch 6/23 Acc: 0.5600 | Macro-F1: 0.4402
Batch 7/23 Acc: 0.5500 | Macro-F1: 0.4382
Batch 8/23 Acc: 0.4800 | Macro-F1: 0.4002
Batch 9/23 Acc: 0.4400 | Macro-F1: 0.4352
Batch 10/23 Acc: 0.5100 | Macro-F1: 0.4273
Batch 11/23 Acc: 0.6100 | Macro-F1: 0.5348
Batch 12/23 Acc: 0.4600 | Macro-F1: 0.3672
Batch 13/23 Acc: 0.4300 | Macro-F1: 0.2947
Batch 14/23 Acc: 0.4200 | Macro-F1: 0.3592
Batch 15/23 Acc: 0.4700 | Macro-F1: 0.4380
Batch 16/23 Acc: 0.5600 | Macro-F1: 0.4838
Batch 17/23 Acc: 0.6500 | Macro-F1: 0.3783
Batch 18/23 Acc: 0.3600 | Macro-F1: 0.3162
Batch 19/23 Acc: 0.6700 | Macro-F1: 0.5307
Batch 20/23 Acc: 0.5300 | Macro-F1: 0.4306
Batch 21/23 Acc: 0.4400 | Macro-F1: 0.3622
Batch 22/23 Acc: 0.8000 | Macro-F1: 0.5000
Final True Accuracy: 0.5156 | Macro F1 Score: 0.4525
best_loss [1.6677252054214478]
{1: {1: 0.5156462788581848}}
{1: {1: 0.5156462788581848}}
########################################################################################
seed: 1 | split 1 : 0.5156462788581848
# Seed 1 Muti Split Final Acc: 0.5156±0.0000
########################################################################################
There's only one result, it's recommended to try several seeds.
split: 1 | seed 1 : 0.5156462788581848
# Split 1 Muti Seed Acc without min value: 0.5156±0.0000
########################################################################################
