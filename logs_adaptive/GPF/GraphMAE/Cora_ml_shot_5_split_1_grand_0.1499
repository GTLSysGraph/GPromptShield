load LLC or attacked shot data with default split
{'scenario': 'poisoning', 'split': 0, 'adaptive_attack_model': 'grand', 'ptb_rate': 0.1499}
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7

Data(x=[2485, 1433], edge_index=[2, 13915], y=[2485], train_mask=[2485], val_mask=[2485], test_mask=[2485])
===========================================================================================================
Number of nodes: 2485
Number of edges: 13915
Average node degree: 5.60
Has isolated nodes: False
Has self-loops: True
Is undirected: True
None
tensor([1756,  307,   33, 1404,  188, 2052,  775,  774, 2081, 1717, 2068,  689,
         254, 1280,  225,  870, 2131, 1445, 1204, 1459, 1394, 1120,  728, 1165,
        1540, 2302, 1798,  937, 1929, 1764, 1142, 2143, 1830,  532,  803])
tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4,
        4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6])
len train nodes: 35
len val   nodes: 245
len test  nodes: 2205
Successfully loaded pre-trained weights!
prepare induce graph data is finished!
run GPF
Epoch 001 |  Time(s) 0.7987 | GPF Loss 1.9460  
Epoch 002 |  Time(s) 0.0384 | GPF Loss 1.9432  
Epoch 003 |  Time(s) 0.0353 | GPF Loss 1.9399  
Epoch 004 |  Time(s) 0.0349 | GPF Loss 1.9360  
Epoch 005 |  Time(s) 0.0337 | GPF Loss 1.9316  
Epoch 006 |  Time(s) 0.0333 | GPF Loss 1.9265  
Epoch 007 |  Time(s) 0.0521 | GPF Loss 1.9209  
Epoch 008 |  Time(s) 0.0372 | GPF Loss 1.9152  
Epoch 009 |  Time(s) 0.0373 | GPF Loss 1.9098  
Epoch 010 |  Time(s) 0.0360 | GPF Loss 1.9046  
Epoch 011 |  Time(s) 0.0347 | GPF Loss 1.9001  
Epoch 012 |  Time(s) 0.0359 | GPF Loss 1.8934  
Epoch 013 |  Time(s) 0.0337 | GPF Loss 1.8895  
Epoch 014 |  Time(s) 0.0339 | GPF Loss 1.8860  
Epoch 015 |  Time(s) 0.0370 | GPF Loss 1.8782  
Epoch 016 |  Time(s) 0.0333 | GPF Loss 1.8763  
Epoch 017 |  Time(s) 0.0332 | GPF Loss 1.8722  
Epoch 018 |  Time(s) 0.0326 | GPF Loss 1.8643  
Epoch 019 |  Time(s) 0.0323 | GPF Loss 1.8652  
Epoch 020 |  Time(s) 0.0322 | GPF Loss 1.8563  
Epoch 021 |  Time(s) 0.0349 | GPF Loss 1.8536  
Epoch 022 |  Time(s) 0.0332 | GPF Loss 1.8481  
Epoch 023 |  Time(s) 0.0322 | GPF Loss 1.8430  
Epoch 024 |  Time(s) 0.0321 | GPF Loss 1.8406  
Epoch 025 |  Time(s) 0.0318 | GPF Loss 1.8337  
Epoch 026 |  Time(s) 0.0321 | GPF Loss 1.8325  
Epoch 027 |  Time(s) 0.0332 | GPF Loss 1.8291  
Epoch 028 |  Time(s) 0.0320 | GPF Loss 1.8203  
Epoch 029 |  Time(s) 0.0327 | GPF Loss 1.8209  
Epoch 030 |  Time(s) 0.0323 | GPF Loss 1.8151  
Epoch 031 |  Time(s) 0.0318 | GPF Loss 1.8097  
Epoch 032 |  Time(s) 0.0323 | GPF Loss 1.8107  
Epoch 033 |  Time(s) 0.0320 | GPF Loss 1.8029  
Epoch 034 |  Time(s) 0.0320 | GPF Loss 1.7979  
Epoch 035 |  Time(s) 0.0327 | GPF Loss 1.7984  
Epoch 036 |  Time(s) 0.0377 | GPF Loss 1.7886  
Epoch 037 |  Time(s) 0.0321 | GPF Loss 1.7874  
Epoch 038 |  Time(s) 0.0327 | GPF Loss 1.7835  
Epoch 039 |  Time(s) 0.0316 | GPF Loss 1.7776  
Epoch 040 |  Time(s) 0.0313 | GPF Loss 1.7746  
Epoch 041 |  Time(s) 0.0305 | GPF Loss 1.7708  
Epoch 042 |  Time(s) 0.0318 | GPF Loss 1.7664  
Epoch 043 |  Time(s) 0.0330 | GPF Loss 1.7621  
Epoch 044 |  Time(s) 0.0347 | GPF Loss 1.7594  
Epoch 045 |  Time(s) 0.0346 | GPF Loss 1.7560  
Epoch 046 |  Time(s) 0.0316 | GPF Loss 1.7515  
Epoch 047 |  Time(s) 0.0338 | GPF Loss 1.7473  
Epoch 048 |  Time(s) 0.0356 | GPF Loss 1.7447  
Epoch 049 |  Time(s) 0.0324 | GPF Loss 1.7421  
Epoch 050 |  Time(s) 0.0310 | GPF Loss 1.7388  
Epoch 051 |  Time(s) 0.0327 | GPF Loss 1.7365  
Epoch 052 |  Time(s) 0.0315 | GPF Loss 1.7378  
Epoch 053 |  Time(s) 0.0326 | GPF Loss 1.7369  
Epoch 054 |  Time(s) 0.0304 | GPF Loss 1.7280  
Epoch 055 |  Time(s) 0.0318 | GPF Loss 1.7241  
Epoch 056 |  Time(s) 0.0355 | GPF Loss 1.7216  
Epoch 057 |  Time(s) 0.0323 | GPF Loss 1.7176  
Epoch 058 |  Time(s) 0.0316 | GPF Loss 1.7156  
Epoch 059 |  Time(s) 0.0325 | GPF Loss 1.7171  
Epoch 060 |  Time(s) 0.0313 | GPF Loss 1.7142  
Epoch 061 |  Time(s) 0.0317 | GPF Loss 1.7086  
Epoch 062 |  Time(s) 0.0346 | GPF Loss 1.7076  
Epoch 063 |  Time(s) 0.0339 | GPF Loss 1.7018  
Epoch 064 |  Time(s) 0.0318 | GPF Loss 1.7022  
Epoch 065 |  Time(s) 0.0375 | GPF Loss 1.7019  
Epoch 066 |  Time(s) 0.0311 | GPF Loss 1.7028  
Epoch 067 |  Time(s) 0.0309 | GPF Loss 1.7025  
Epoch 068 |  Time(s) 0.0352 | GPF Loss 1.7134  
Epoch 069 |  Time(s) 0.0305 | GPF Loss 1.6959  
Epoch 070 |  Time(s) 0.0304 | GPF Loss 1.6927  
Epoch 071 |  Time(s) 0.0313 | GPF Loss 1.6960  
Epoch 072 |  Time(s) 0.0300 | GPF Loss 1.6963  
Epoch 073 |  Time(s) 0.0374 | GPF Loss 1.6889  
Epoch 074 |  Time(s) 0.0321 | GPF Loss 1.7104  
Epoch 075 |  Time(s) 0.0364 | GPF Loss 1.6844  
Epoch 076 |  Time(s) 0.0321 | GPF Loss 1.6898  
Epoch 077 |  Time(s) 0.0323 | GPF Loss 1.6961  
Epoch 078 |  Time(s) 0.0365 | GPF Loss 1.7028  
Epoch 079 |  Time(s) 0.0316 | GPF Loss 1.6826  
Epoch 080 |  Time(s) 0.0423 | GPF Loss 1.7031  
Epoch 081 |  Time(s) 0.0344 | GPF Loss 1.6863  
Epoch 082 |  Time(s) 0.0325 | GPF Loss 1.6872  
Epoch 083 |  Time(s) 0.0346 | GPF Loss 1.6915  
Epoch 084 |  Time(s) 0.0336 | GPF Loss 1.6954  
Epoch 085 |  Time(s) 0.0330 | GPF Loss 1.6821  
Epoch 086 |  Time(s) 0.0328 | GPF Loss 1.6821  
Epoch 087 |  Time(s) 0.0339 | GPF Loss 1.6864  
Epoch 088 |  Time(s) 0.0362 | GPF Loss 1.6803  
Epoch 089 |  Time(s) 0.0320 | GPF Loss 1.6797  
Epoch 090 |  Time(s) 0.0358 | GPF Loss 1.6779  
Epoch 091 |  Time(s) 0.0426 | GPF Loss 1.6754  
Epoch 092 |  Time(s) 0.0347 | GPF Loss 1.6704  
Epoch 093 |  Time(s) 0.0338 | GPF Loss 1.6659  
Epoch 094 |  Time(s) 0.0363 | GPF Loss 1.6766  
Epoch 095 |  Time(s) 0.0331 | GPF Loss 1.6644  
Epoch 096 |  Time(s) 0.0330 | GPF Loss 1.6613  
Epoch 097 |  Time(s) 0.0351 | GPF Loss 1.6702  
Epoch 098 |  Time(s) 0.0331 | GPF Loss 1.6623  
Epoch 099 |  Time(s) 0.0368 | GPF Loss 1.6594  
Epoch 100 |  Time(s) 0.0379 | GPF Loss 1.6599  
Batch 0/23 Acc: 0.2600 | Macro-F1: 0.2476
Batch 1/23 Acc: 0.2600 | Macro-F1: 0.2203
Batch 2/23 Acc: 0.1800 | Macro-F1: 0.1605
Batch 3/23 Acc: 0.2600 | Macro-F1: 0.2163
Batch 4/23 Acc: 0.2800 | Macro-F1: 0.2678
Batch 5/23 Acc: 0.3000 | Macro-F1: 0.1760
Batch 6/23 Acc: 0.2300 | Macro-F1: 0.2108
Batch 7/23 Acc: 0.2500 | Macro-F1: 0.2323
Batch 8/23 Acc: 0.2000 | Macro-F1: 0.1358
Batch 9/23 Acc: 0.3400 | Macro-F1: 0.3023
Batch 10/23 Acc: 0.2500 | Macro-F1: 0.2168
Batch 11/23 Acc: 0.1500 | Macro-F1: 0.1645
Batch 12/23 Acc: 0.2000 | Macro-F1: 0.1952
Batch 13/23 Acc: 0.2800 | Macro-F1: 0.2111
Batch 14/23 Acc: 0.2900 | Macro-F1: 0.2324
Batch 15/23 Acc: 0.3000 | Macro-F1: 0.2799
Batch 16/23 Acc: 0.2600 | Macro-F1: 0.2313
Batch 17/23 Acc: 0.1800 | Macro-F1: 0.1673
Batch 18/23 Acc: 0.3700 | Macro-F1: 0.1645
Batch 19/23 Acc: 0.3300 | Macro-F1: 0.2578
Batch 20/23 Acc: 0.1800 | Macro-F1: 0.1860
Batch 21/23 Acc: 0.1900 | Macro-F1: 0.1535
Batch 22/23 Acc: 0.0000 | Macro-F1: 0.0000
Final True Accuracy: 0.2512 | Macro F1 Score: 0.2233
best_loss [1.6598931550979614]
{1: {1: 0.2512471675872803}}
{1: {1: 0.2512471675872803}}
########################################################################################
seed: 1 | split 1 : 0.2512471675872803
# Seed 1 Muti Split Final Acc: 0.2512±0.0000
########################################################################################
There's only one result, it's recommended to try several seeds.
split: 1 | seed 1 : 0.2512471675872803
# Split 1 Muti Seed Acc without min value: 0.2512±0.0000
########################################################################################
