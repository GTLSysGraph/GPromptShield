load LLC or attacked shot data with default split
{'scenario': 'poisoning', 'split': 0, 'adaptive_attack_model': 'gnn_guard', 'ptb_rate': 0.1499}
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7

Data(x=[2485, 1433], edge_index=[2, 14119], y=[2485], train_mask=[2485], val_mask=[2485], test_mask=[2485])
===========================================================================================================
Number of nodes: 2485
Number of edges: 14119
Average node degree: 5.68
Has isolated nodes: False
Has self-loops: True
Is undirected: True
None
tensor([1756,  307,   33, 1404,  188, 2052,  775,  774, 2081, 1717, 2068,  689,
         254, 1280,  225,  870, 2131, 1445, 1204, 1459, 1394, 1120,  728, 1165,
        1540, 2302, 1798,  937, 1929, 1764, 1142, 2143, 1830,  532,  803])
tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4,
        4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6])
len train nodes: 35
len val   nodes: 245
len test  nodes: 2205
Successfully loaded pre-trained weights!
prepare induce graph data is finished!
run GPF
Epoch 001 |  Time(s) 0.8911 | GPF Loss 1.9459  
Epoch 002 |  Time(s) 0.0413 | GPF Loss 1.9431  
Epoch 003 |  Time(s) 0.0360 | GPF Loss 1.9398  
Epoch 004 |  Time(s) 0.0348 | GPF Loss 1.9359  
Epoch 005 |  Time(s) 0.0356 | GPF Loss 1.9317  
Epoch 006 |  Time(s) 0.0340 | GPF Loss 1.9268  
Epoch 007 |  Time(s) 0.0338 | GPF Loss 1.9212  
Epoch 008 |  Time(s) 0.0341 | GPF Loss 1.9157  
Epoch 009 |  Time(s) 0.0339 | GPF Loss 1.9101  
Epoch 010 |  Time(s) 0.0337 | GPF Loss 1.9040  
Epoch 011 |  Time(s) 0.0334 | GPF Loss 1.8993  
Epoch 012 |  Time(s) 0.0332 | GPF Loss 1.8929  
Epoch 013 |  Time(s) 0.0331 | GPF Loss 1.8864  
Epoch 014 |  Time(s) 0.0330 | GPF Loss 1.8807  
Epoch 015 |  Time(s) 0.0330 | GPF Loss 1.8761  
Epoch 016 |  Time(s) 0.0334 | GPF Loss 1.8725  
Epoch 017 |  Time(s) 0.0333 | GPF Loss 1.8637  
Epoch 018 |  Time(s) 0.0341 | GPF Loss 1.8653  
Epoch 019 |  Time(s) 0.0333 | GPF Loss 1.8560  
Epoch 020 |  Time(s) 0.0342 | GPF Loss 1.8536  
Epoch 021 |  Time(s) 0.0334 | GPF Loss 1.8439  
Epoch 022 |  Time(s) 0.0336 | GPF Loss 1.8437  
Epoch 023 |  Time(s) 0.0332 | GPF Loss 1.8395  
Epoch 024 |  Time(s) 0.0344 | GPF Loss 1.8335  
Epoch 025 |  Time(s) 0.0347 | GPF Loss 1.8285  
Epoch 026 |  Time(s) 0.0343 | GPF Loss 1.8221  
Epoch 027 |  Time(s) 0.0341 | GPF Loss 1.8227  
Epoch 028 |  Time(s) 0.0360 | GPF Loss 1.8132  
Epoch 029 |  Time(s) 0.0339 | GPF Loss 1.8114  
Epoch 030 |  Time(s) 0.0339 | GPF Loss 1.8061  
Epoch 031 |  Time(s) 0.0375 | GPF Loss 1.8041  
Epoch 032 |  Time(s) 0.0337 | GPF Loss 1.7988  
Epoch 033 |  Time(s) 0.0366 | GPF Loss 1.7981  
Epoch 034 |  Time(s) 0.0442 | GPF Loss 1.7882  
Epoch 035 |  Time(s) 0.0330 | GPF Loss 1.7897  
Epoch 036 |  Time(s) 0.0341 | GPF Loss 1.7826  
Epoch 037 |  Time(s) 0.0364 | GPF Loss 1.7803  
Epoch 038 |  Time(s) 0.0366 | GPF Loss 1.7763  
Epoch 039 |  Time(s) 0.0369 | GPF Loss 1.7766  
Epoch 040 |  Time(s) 0.0365 | GPF Loss 1.7663  
Epoch 041 |  Time(s) 0.0363 | GPF Loss 1.7673  
Epoch 042 |  Time(s) 0.0365 | GPF Loss 1.7617  
Epoch 043 |  Time(s) 0.0395 | GPF Loss 1.7567  
Epoch 044 |  Time(s) 0.0350 | GPF Loss 1.7561  
Epoch 045 |  Time(s) 0.0355 | GPF Loss 1.7498  
Epoch 046 |  Time(s) 0.0357 | GPF Loss 1.7503  
Epoch 047 |  Time(s) 0.0383 | GPF Loss 1.7454  
Epoch 048 |  Time(s) 0.0316 | GPF Loss 1.7420  
Epoch 049 |  Time(s) 0.0349 | GPF Loss 1.7386  
Epoch 050 |  Time(s) 0.0343 | GPF Loss 1.7341  
Epoch 051 |  Time(s) 0.0335 | GPF Loss 1.7335  
Epoch 052 |  Time(s) 0.0352 | GPF Loss 1.7296  
Epoch 053 |  Time(s) 0.0409 | GPF Loss 1.7305  
Epoch 054 |  Time(s) 0.0332 | GPF Loss 1.7283  
Epoch 055 |  Time(s) 0.0320 | GPF Loss 1.7247  
Epoch 056 |  Time(s) 0.0341 | GPF Loss 1.7189  
Epoch 057 |  Time(s) 0.0337 | GPF Loss 1.7194  
Epoch 058 |  Time(s) 0.0468 | GPF Loss 1.7143  
Epoch 059 |  Time(s) 0.0315 | GPF Loss 1.7161  
Epoch 060 |  Time(s) 0.0376 | GPF Loss 1.7071  
Epoch 061 |  Time(s) 0.0327 | GPF Loss 1.7125  
Epoch 062 |  Time(s) 0.0392 | GPF Loss 1.7085  
Epoch 063 |  Time(s) 0.0402 | GPF Loss 1.7124  
Epoch 064 |  Time(s) 0.0375 | GPF Loss 1.7031  
Epoch 065 |  Time(s) 0.0355 | GPF Loss 1.7064  
Epoch 066 |  Time(s) 0.0329 | GPF Loss 1.6967  
Epoch 067 |  Time(s) 0.0333 | GPF Loss 1.6993  
Epoch 068 |  Time(s) 0.0364 | GPF Loss 1.6934  
Epoch 069 |  Time(s) 0.0334 | GPF Loss 1.6969  
Epoch 070 |  Time(s) 0.0404 | GPF Loss 1.6919  
Epoch 071 |  Time(s) 0.0359 | GPF Loss 1.6884  
Epoch 072 |  Time(s) 0.0360 | GPF Loss 1.6894  
Epoch 073 |  Time(s) 0.0441 | GPF Loss 1.6843  
Epoch 074 |  Time(s) 0.0354 | GPF Loss 1.6852  
Epoch 075 |  Time(s) 0.0349 | GPF Loss 1.6825  
Epoch 076 |  Time(s) 0.0409 | GPF Loss 1.6777  
Epoch 077 |  Time(s) 0.0448 | GPF Loss 1.6802  
Epoch 078 |  Time(s) 0.0346 | GPF Loss 1.6763  
Epoch 079 |  Time(s) 0.0337 | GPF Loss 1.6744  
Epoch 080 |  Time(s) 0.0338 | GPF Loss 1.6748  
Epoch 081 |  Time(s) 0.0356 | GPF Loss 1.6700  
Epoch 082 |  Time(s) 0.0350 | GPF Loss 1.6689  
Epoch 083 |  Time(s) 0.0338 | GPF Loss 1.6687  
Epoch 084 |  Time(s) 0.0338 | GPF Loss 1.6666  
Epoch 085 |  Time(s) 0.0336 | GPF Loss 1.6639  
Epoch 086 |  Time(s) 0.0339 | GPF Loss 1.6641  
Epoch 087 |  Time(s) 0.0338 | GPF Loss 1.6630  
Epoch 088 |  Time(s) 0.0380 | GPF Loss 1.6598  
Epoch 089 |  Time(s) 0.0369 | GPF Loss 1.6597  
Epoch 090 |  Time(s) 0.0348 | GPF Loss 1.6599  
Epoch 091 |  Time(s) 0.0346 | GPF Loss 1.6559  
Epoch 092 |  Time(s) 0.0342 | GPF Loss 1.6548  
Epoch 093 |  Time(s) 0.0370 | GPF Loss 1.6578  
Epoch 094 |  Time(s) 0.0496 | GPF Loss 1.6551  
Epoch 095 |  Time(s) 0.0373 | GPF Loss 1.6507  
Epoch 096 |  Time(s) 0.0360 | GPF Loss 1.6512  
Epoch 097 |  Time(s) 0.0359 | GPF Loss 1.6500  
Epoch 098 |  Time(s) 0.0362 | GPF Loss 1.6489  
Epoch 099 |  Time(s) 0.0361 | GPF Loss 1.6468  
Epoch 100 |  Time(s) 0.0362 | GPF Loss 1.6458  
Batch 0/23 Acc: 0.4600 | Macro-F1: 0.4464
Batch 1/23 Acc: 0.4800 | Macro-F1: 0.4250
Batch 2/23 Acc: 0.5500 | Macro-F1: 0.4626
Batch 3/23 Acc: 0.4500 | Macro-F1: 0.4131
Batch 4/23 Acc: 0.7100 | Macro-F1: 0.5690
Batch 5/23 Acc: 0.4800 | Macro-F1: 0.2814
Batch 6/23 Acc: 0.5500 | Macro-F1: 0.4491
Batch 7/23 Acc: 0.5700 | Macro-F1: 0.4739
Batch 8/23 Acc: 0.5000 | Macro-F1: 0.4019
Batch 9/23 Acc: 0.3800 | Macro-F1: 0.3489
Batch 10/23 Acc: 0.5500 | Macro-F1: 0.4687
Batch 11/23 Acc: 0.4600 | Macro-F1: 0.3703
Batch 12/23 Acc: 0.4700 | Macro-F1: 0.3799
Batch 13/23 Acc: 0.4000 | Macro-F1: 0.3073
Batch 14/23 Acc: 0.4800 | Macro-F1: 0.4280
Batch 15/23 Acc: 0.4700 | Macro-F1: 0.4286
Batch 16/23 Acc: 0.6000 | Macro-F1: 0.4592
Batch 17/23 Acc: 0.7700 | Macro-F1: 0.4798
Batch 18/23 Acc: 0.5200 | Macro-F1: 0.4159
Batch 19/23 Acc: 0.5700 | Macro-F1: 0.4230
Batch 20/23 Acc: 0.4100 | Macro-F1: 0.3974
Batch 21/23 Acc: 0.3700 | Macro-F1: 0.2986
Batch 22/23 Acc: 0.2000 | Macro-F1: 0.0800
Final True Accuracy: 0.5084 | Macro F1 Score: 0.4512
best_loss [1.6457678079605103]
{1: {1: 0.5083900094032288}}
{1: {1: 0.5083900094032288}}
########################################################################################
seed: 1 | split 1 : 0.5083900094032288
# Seed 1 Muti Split Final Acc: 0.5084±0.0000
########################################################################################
There's only one result, it's recommended to try several seeds.
split: 1 | seed 1 : 0.5083900094032288
# Split 1 Muti Seed Acc without min value: 0.5084±0.0000
########################################################################################
