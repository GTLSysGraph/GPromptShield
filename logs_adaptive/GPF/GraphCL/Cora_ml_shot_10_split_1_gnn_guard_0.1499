load LLC or attacked shot data with default split
{'scenario': 'poisoning', 'split': 0, 'adaptive_attack_model': 'gnn_guard', 'ptb_rate': 0.1499}
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7

Data(x=[2485, 1433], edge_index=[2, 14119], y=[2485], train_mask=[2485], val_mask=[2485], test_mask=[2485])
===========================================================================================================
Number of nodes: 2485
Number of edges: 14119
Average node degree: 5.68
Has isolated nodes: False
Has self-loops: True
Is undirected: True
None
tensor([1756,  307,   33, 1404,  188,  392, 2426,  422, 1970, 1832, 2052,  775,
         774, 2081, 1717, 1530, 1793, 1991, 2055, 1901, 2068,  689,  254, 1280,
         225,  252, 1493, 1286,  849, 1975,  870, 2131, 1445, 1204, 1459, 1695,
         432, 1570, 1701, 2093, 1394, 1120,  728, 1165, 1540,  934, 2001,  428,
        1058, 1297, 2302, 1798,  937, 1929, 1764, 2155, 1979, 1085, 1866,  145,
        1142, 2143, 1830,  532,  803, 2058, 1461, 1358, 1672,  682])
tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,
        4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6])
len train nodes: 70
len val   nodes: 241
len test  nodes: 2174
Successfully loaded pre-trained weights!
prepare induce graph data is finished!
run GPF
Epoch 001 |  Time(s) 0.9069 | GPF Loss 1.9235  
Epoch 002 |  Time(s) 0.0742 | GPF Loss 1.9124  
Epoch 003 |  Time(s) 0.0708 | GPF Loss 1.8630  
Epoch 004 |  Time(s) 0.0714 | GPF Loss 1.9587  
Epoch 005 |  Time(s) 0.0713 | GPF Loss 1.8213  
Epoch 006 |  Time(s) 0.0713 | GPF Loss 1.8658  
Epoch 007 |  Time(s) 0.0716 | GPF Loss 1.8349  
Epoch 008 |  Time(s) 0.0720 | GPF Loss 1.8894  
Epoch 009 |  Time(s) 0.0740 | GPF Loss 1.8687  
Epoch 010 |  Time(s) 0.0733 | GPF Loss 1.8612  
Epoch 011 |  Time(s) 0.0730 | GPF Loss 1.8331  
Epoch 012 |  Time(s) 0.0730 | GPF Loss 1.8639  
Epoch 013 |  Time(s) 0.0659 | GPF Loss 1.8165  
Epoch 014 |  Time(s) 0.0670 | GPF Loss 1.8326  
Epoch 015 |  Time(s) 0.0940 | GPF Loss 1.8386  
Epoch 016 |  Time(s) 0.0809 | GPF Loss 1.8286  
Epoch 017 |  Time(s) 0.1343 | GPF Loss 1.8201  
Epoch 018 |  Time(s) 0.0931 | GPF Loss 1.8188  
Epoch 019 |  Time(s) 0.0806 | GPF Loss 1.8192  
Epoch 020 |  Time(s) 0.1131 | GPF Loss 1.8173  
Epoch 021 |  Time(s) 0.0778 | GPF Loss 1.8125  
Epoch 022 |  Time(s) 0.0823 | GPF Loss 1.7999  
Epoch 023 |  Time(s) 0.1092 | GPF Loss 1.7946  
Epoch 024 |  Time(s) 0.0961 | GPF Loss 1.7919  
Epoch 025 |  Time(s) 0.0825 | GPF Loss 1.7766  
Epoch 026 |  Time(s) 0.0782 | GPF Loss 1.7696  
Epoch 027 |  Time(s) 0.0722 | GPF Loss 1.7652  
Epoch 028 |  Time(s) 0.0731 | GPF Loss 1.7508  
Epoch 029 |  Time(s) 0.0726 | GPF Loss 1.7504  
Epoch 030 |  Time(s) 0.0721 | GPF Loss 1.7482  
Epoch 031 |  Time(s) 0.0709 | GPF Loss 1.7390  
Epoch 032 |  Time(s) 0.0691 | GPF Loss 1.7383  
Epoch 033 |  Time(s) 0.0854 | GPF Loss 1.7249  
Epoch 034 |  Time(s) 0.1092 | GPF Loss 1.7306  
Epoch 035 |  Time(s) 0.0959 | GPF Loss 1.7179  
Epoch 036 |  Time(s) 0.0973 | GPF Loss 1.7227  
Epoch 037 |  Time(s) 0.0835 | GPF Loss 1.7383  
Epoch 038 |  Time(s) 0.0757 | GPF Loss 1.8875  
Epoch 039 |  Time(s) 0.0821 | GPF Loss 1.8119  
Epoch 040 |  Time(s) 0.0797 | GPF Loss 1.8570  
Epoch 041 |  Time(s) 0.0771 | GPF Loss 1.9140  
Epoch 042 |  Time(s) 0.0819 | GPF Loss 1.9179  
Epoch 043 |  Time(s) 0.0730 | GPF Loss 1.9152  
Epoch 044 |  Time(s) 0.0962 | GPF Loss 1.8982  
Epoch 045 |  Time(s) 0.0822 | GPF Loss 1.9197  
Epoch 046 |  Time(s) 0.0830 | GPF Loss 1.9013  
Epoch 047 |  Time(s) 0.0801 | GPF Loss 1.9193  
Epoch 048 |  Time(s) 0.0802 | GPF Loss 1.9502  
Epoch 049 |  Time(s) 0.0802 | GPF Loss 1.9218  
Epoch 050 |  Time(s) 0.0886 | GPF Loss 2.0055  
Epoch 051 |  Time(s) 0.0824 | GPF Loss 2.0223  
Epoch 052 |  Time(s) 0.0825 | GPF Loss 2.0226  
Epoch 053 |  Time(s) 0.0778 | GPF Loss 2.0226  
Epoch 054 |  Time(s) 0.0788 | GPF Loss 2.0226  
----------------------------------------------------------------------------------------------------
Early stopping at 55 eopch!
Batch 0/22 Acc: 0.1400 | Macro-F1: 0.0351
Batch 1/22 Acc: 0.1100 | Macro-F1: 0.0283
Batch 2/22 Acc: 0.0900 | Macro-F1: 0.0236
Batch 3/22 Acc: 0.0800 | Macro-F1: 0.0212
Batch 4/22 Acc: 0.3800 | Macro-F1: 0.0787
Batch 5/22 Acc: 0.1500 | Macro-F1: 0.0373
Batch 6/22 Acc: 0.2000 | Macro-F1: 0.0476
Batch 7/22 Acc: 0.1200 | Macro-F1: 0.0306
Batch 8/22 Acc: 0.1200 | Macro-F1: 0.0306
Batch 9/22 Acc: 0.1400 | Macro-F1: 0.0351
Batch 10/22 Acc: 0.1000 | Macro-F1: 0.0260
Batch 11/22 Acc: 0.1300 | Macro-F1: 0.0329
Batch 12/22 Acc: 0.1000 | Macro-F1: 0.0260
Batch 13/22 Acc: 0.0800 | Macro-F1: 0.0212
Batch 14/22 Acc: 0.1900 | Macro-F1: 0.0456
Batch 15/22 Acc: 0.1300 | Macro-F1: 0.0329
Batch 16/22 Acc: 0.5300 | Macro-F1: 0.0990
Batch 17/22 Acc: 0.3500 | Macro-F1: 0.0741
Batch 18/22 Acc: 0.1700 | Macro-F1: 0.0415
Batch 19/22 Acc: 0.0600 | Macro-F1: 0.0162
Batch 20/22 Acc: 0.1600 | Macro-F1: 0.0394
Batch 21/22 Acc: 0.1216 | Macro-F1: 0.0310
Final True Accuracy: 0.1665 | Macro F1 Score: 0.0408
best_loss [2.022564172744751]
{1: {1: 0.1665133386850357}}
{1: {1: 0.1665133386850357}}
########################################################################################
seed: 1 | split 1 : 0.1665133386850357
# Seed 1 Muti Split Final Acc: 0.1665±0.0000
########################################################################################
There's only one result, it's recommended to try several seeds.
split: 1 | seed 1 : 0.1665133386850357
# Split 1 Muti Seed Acc without min value: 0.1665±0.0000
########################################################################################
