load LLC or attacked shot data with default split
{'scenario': 'poisoning', 'split': 0, 'adaptive_attack_model': 'svd_gcn', 'ptb_rate': 0.1274}
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7

Data(x=[2485, 1433], edge_index=[2, 13915], y=[2485], train_mask=[2485], val_mask=[2485], test_mask=[2485])
===========================================================================================================
Number of nodes: 2485
Number of edges: 13915
Average node degree: 5.60
Has isolated nodes: False
Has self-loops: True
Is undirected: True
None
tensor([1756,  307,   33, 1404,  188,  392, 2426,  422, 1970, 1832, 2052,  775,
         774, 2081, 1717, 1530, 1793, 1991, 2055, 1901, 2068,  689,  254, 1280,
         225,  252, 1493, 1286,  849, 1975,  870, 2131, 1445, 1204, 1459, 1695,
         432, 1570, 1701, 2093, 1394, 1120,  728, 1165, 1540,  934, 2001,  428,
        1058, 1297, 2302, 1798,  937, 1929, 1764, 2155, 1979, 1085, 1866,  145,
        1142, 2143, 1830,  532,  803, 2058, 1461, 1358, 1672,  682])
tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,
        4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6])
len train nodes: 70
len val   nodes: 241
len test  nodes: 2174
Successfully loaded pre-trained weights!
prepare induce graph data is finished!
run GPF
Epoch 001 |  Time(s) 0.9523 | GPF Loss 1.9333  
Epoch 002 |  Time(s) 0.0710 | GPF Loss 1.9317  
Epoch 003 |  Time(s) 0.0727 | GPF Loss 1.9499  
Epoch 004 |  Time(s) 0.0796 | GPF Loss 1.8855  
Epoch 005 |  Time(s) 0.0748 | GPF Loss 1.8462  
Epoch 006 |  Time(s) 0.0737 | GPF Loss 1.8836  
Epoch 007 |  Time(s) 0.0756 | GPF Loss 1.8352  
Epoch 008 |  Time(s) 0.0748 | GPF Loss 1.8556  
Epoch 009 |  Time(s) 0.0743 | GPF Loss 1.8440  
Epoch 010 |  Time(s) 0.0701 | GPF Loss 1.8408  
Epoch 011 |  Time(s) 0.0776 | GPF Loss 1.8269  
Epoch 012 |  Time(s) 0.1056 | GPF Loss 1.8212  
Epoch 013 |  Time(s) 0.0824 | GPF Loss 1.8109  
Epoch 014 |  Time(s) 0.0724 | GPF Loss 1.7868  
Epoch 015 |  Time(s) 0.0886 | GPF Loss 1.7704  
Epoch 016 |  Time(s) 0.0747 | GPF Loss 1.7769  
Epoch 017 |  Time(s) 0.0733 | GPF Loss 1.7556  
Epoch 018 |  Time(s) 0.0678 | GPF Loss 1.7337  
Epoch 019 |  Time(s) 0.0726 | GPF Loss 1.7359  
Epoch 020 |  Time(s) 0.0789 | GPF Loss 1.7558  
Epoch 021 |  Time(s) 0.0763 | GPF Loss 1.7200  
Epoch 022 |  Time(s) 0.0788 | GPF Loss 1.7105  
Epoch 023 |  Time(s) 0.0798 | GPF Loss 1.6927  
Epoch 024 |  Time(s) 0.1191 | GPF Loss 1.6689  
Epoch 025 |  Time(s) 0.0809 | GPF Loss 1.6528  
Epoch 026 |  Time(s) 0.0922 | GPF Loss 1.6465  
Epoch 027 |  Time(s) 0.0879 | GPF Loss 1.6192  
Epoch 028 |  Time(s) 0.0799 | GPF Loss 1.6181  
Epoch 029 |  Time(s) 0.0798 | GPF Loss 1.5971  
Epoch 030 |  Time(s) 0.0820 | GPF Loss 1.5923  
Epoch 031 |  Time(s) 0.0796 | GPF Loss 1.5853  
Epoch 032 |  Time(s) 0.0785 | GPF Loss 1.5852  
Epoch 033 |  Time(s) 0.0760 | GPF Loss 1.6001  
Epoch 034 |  Time(s) 0.0728 | GPF Loss 1.6374  
Epoch 035 |  Time(s) 0.0778 | GPF Loss 1.5936  
Epoch 036 |  Time(s) 0.0738 | GPF Loss 1.6319  
Epoch 037 |  Time(s) 0.0787 | GPF Loss 1.6252  
Epoch 038 |  Time(s) 0.0920 | GPF Loss 1.6223  
Epoch 039 |  Time(s) 0.0735 | GPF Loss 1.6220  
Epoch 040 |  Time(s) 0.0811 | GPF Loss 1.6209  
Epoch 041 |  Time(s) 0.0784 | GPF Loss 1.6353  
Epoch 042 |  Time(s) 0.0957 | GPF Loss 1.6369  
Epoch 043 |  Time(s) 0.0817 | GPF Loss 1.6440  
Epoch 044 |  Time(s) 0.0804 | GPF Loss 1.6370  
Epoch 045 |  Time(s) 0.0769 | GPF Loss 1.6674  
Epoch 046 |  Time(s) 0.0805 | GPF Loss 1.6466  
Epoch 047 |  Time(s) 0.0764 | GPF Loss 1.6873  
Epoch 048 |  Time(s) 0.1457 | GPF Loss 1.6883  
Epoch 049 |  Time(s) 0.1382 | GPF Loss 1.6790  
Epoch 050 |  Time(s) 0.0857 | GPF Loss 1.6437  
Epoch 051 |  Time(s) 0.0981 | GPF Loss 1.6352  
----------------------------------------------------------------------------------------------------
Early stopping at 52 eopch!
Batch 0/22 Acc: 0.2700 | Macro-F1: 0.2760
Batch 1/22 Acc: 0.3800 | Macro-F1: 0.3387
Batch 2/22 Acc: 0.3400 | Macro-F1: 0.2923
Batch 3/22 Acc: 0.3600 | Macro-F1: 0.3097
Batch 4/22 Acc: 0.5400 | Macro-F1: 0.3676
Batch 5/22 Acc: 0.5100 | Macro-F1: 0.2821
Batch 6/22 Acc: 0.4300 | Macro-F1: 0.3199
Batch 7/22 Acc: 0.3600 | Macro-F1: 0.3318
Batch 8/22 Acc: 0.4400 | Macro-F1: 0.3684
Batch 9/22 Acc: 0.4400 | Macro-F1: 0.3348
Batch 10/22 Acc: 0.2500 | Macro-F1: 0.2547
Batch 11/22 Acc: 0.3300 | Macro-F1: 0.3149
Batch 12/22 Acc: 0.3900 | Macro-F1: 0.3187
Batch 13/22 Acc: 0.2800 | Macro-F1: 0.2666
Batch 14/22 Acc: 0.3800 | Macro-F1: 0.3051
Batch 15/22 Acc: 0.3900 | Macro-F1: 0.3401
Batch 16/22 Acc: 0.5800 | Macro-F1: 0.3674
Batch 17/22 Acc: 0.4600 | Macro-F1: 0.3339
Batch 18/22 Acc: 0.5800 | Macro-F1: 0.3890
Batch 19/22 Acc: 0.4200 | Macro-F1: 0.3338
Batch 20/22 Acc: 0.4600 | Macro-F1: 0.3770
Batch 21/22 Acc: 0.3784 | Macro-F1: 0.3210
Final True Accuracy: 0.4080 | Macro F1 Score: 0.3418
best_loss [1.6893961429595947]
{1: {1: 0.40800368785858154}}
{1: {1: 0.40800368785858154}}
########################################################################################
seed: 1 | split 1 : 0.40800368785858154
# Seed 1 Muti Split Final Acc: 0.4080±0.0000
########################################################################################
There's only one result, it's recommended to try several seeds.
split: 1 | seed 1 : 0.40800368785858154
# Split 1 Muti Seed Acc without min value: 0.4080±0.0000
########################################################################################
