load LLC or attacked shot data with default split
{'scenario': 'poisoning', 'split': 0, 'adaptive_attack_model': 'svd_gcn', 'ptb_rate': 0.12}
======================
Number of graphs: 1
Number of features: 3703
Number of classes: 6

Data(x=[2110, 3703], edge_index=[2, 10326], y=[2110], train_mask=[2110], val_mask=[2110], test_mask=[2110])
===========================================================================================================
Number of nodes: 2110
Number of edges: 10326
Average node degree: 4.89
Has isolated nodes: False
Has self-loops: True
Is undirected: True
None
tensor([ 603,  822, 1332, 1531, 1997,  106, 1133,  742,  739, 1600,  126,  193,
        1407,  564,  820,  333,  423, 1705,  404, 1220,  282,  670,  121,  830,
        1958, 1916, 1218,   88,  466,   72,  623, 1625, 2050, 1835, 1938, 1393,
        1166, 1375,  767,  993,  660, 1056, 1879,  337, 1230, 1788, 1211, 1465,
        1202,  452, 1523, 1441,  191, 1443, 1183,  636, 1708, 1448, 1739, 2053])
tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,
        4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])
len train nodes: 60
len val   nodes: 205
len test  nodes: 1845
Successfully loaded pre-trained weights!
prepare induce graph data is finished!
run GPF
Epoch 001 |  Time(s) 0.9879 | GPF Loss 1.8030  
Epoch 002 |  Time(s) 0.1582 | GPF Loss 1.7886  
Epoch 003 |  Time(s) 0.1455 | GPF Loss 1.7894  
Epoch 004 |  Time(s) 0.1451 | GPF Loss 1.7512  
Epoch 005 |  Time(s) 0.1511 | GPF Loss 1.7128  
Epoch 006 |  Time(s) 0.1435 | GPF Loss 1.6766  
Epoch 007 |  Time(s) 0.1441 | GPF Loss 1.6623  
Epoch 008 |  Time(s) 0.1447 | GPF Loss 1.6716  
Epoch 009 |  Time(s) 0.1455 | GPF Loss 1.6656  
Epoch 010 |  Time(s) 0.1466 | GPF Loss 1.6624  
Epoch 011 |  Time(s) 0.1465 | GPF Loss 1.6590  
Epoch 012 |  Time(s) 0.1488 | GPF Loss 1.6546  
Epoch 013 |  Time(s) 0.1458 | GPF Loss 1.6524  
Epoch 014 |  Time(s) 0.1463 | GPF Loss 1.6287  
Epoch 015 |  Time(s) 0.1416 | GPF Loss 1.6555  
Epoch 016 |  Time(s) 0.1443 | GPF Loss 1.6477  
Epoch 017 |  Time(s) 0.1425 | GPF Loss 1.6520  
Epoch 018 |  Time(s) 0.2010 | GPF Loss 1.6644  
Epoch 019 |  Time(s) 0.1531 | GPF Loss 1.6021  
Epoch 020 |  Time(s) 0.1532 | GPF Loss 1.6418  
Epoch 021 |  Time(s) 0.1489 | GPF Loss 1.6193  
Epoch 022 |  Time(s) 0.1532 | GPF Loss 1.6336  
Epoch 023 |  Time(s) 0.1776 | GPF Loss 1.6001  
Epoch 024 |  Time(s) 0.1607 | GPF Loss 1.5907  
Epoch 025 |  Time(s) 0.1569 | GPF Loss 1.6118  
Epoch 026 |  Time(s) 0.1587 | GPF Loss 1.6137  
Epoch 027 |  Time(s) 0.1588 | GPF Loss 1.6005  
Epoch 028 |  Time(s) 0.1495 | GPF Loss 1.5956  
Epoch 029 |  Time(s) 0.1473 | GPF Loss 1.5960  
Epoch 030 |  Time(s) 0.1530 | GPF Loss 1.5776  
Epoch 031 |  Time(s) 0.1599 | GPF Loss 1.5786  
Epoch 032 |  Time(s) 0.1479 | GPF Loss 1.5829  
Epoch 033 |  Time(s) 0.1485 | GPF Loss 1.5764  
Epoch 034 |  Time(s) 0.2235 | GPF Loss 1.5774  
Epoch 035 |  Time(s) 0.1491 | GPF Loss 1.5595  
Epoch 036 |  Time(s) 0.1448 | GPF Loss 1.5673  
Epoch 037 |  Time(s) 0.1476 | GPF Loss 1.5604  
Epoch 038 |  Time(s) 0.1455 | GPF Loss 1.5580  
Epoch 039 |  Time(s) 0.2011 | GPF Loss 1.5602  
Epoch 040 |  Time(s) 0.1717 | GPF Loss 1.5519  
Epoch 041 |  Time(s) 0.1596 | GPF Loss 1.5550  
Epoch 042 |  Time(s) 0.1535 | GPF Loss 1.5537  
Epoch 043 |  Time(s) 0.1631 | GPF Loss 1.5450  
Epoch 044 |  Time(s) 0.1432 | GPF Loss 1.5516  
Epoch 045 |  Time(s) 0.1450 | GPF Loss 1.5637  
Epoch 046 |  Time(s) 0.1447 | GPF Loss 1.5752  
Epoch 047 |  Time(s) 0.1429 | GPF Loss 1.5441  
Epoch 048 |  Time(s) 0.1446 | GPF Loss 1.5479  
Epoch 049 |  Time(s) 0.1472 | GPF Loss 1.5600  
Epoch 050 |  Time(s) 0.1458 | GPF Loss 1.5374  
Epoch 051 |  Time(s) 0.1478 | GPF Loss 1.5580  
Epoch 052 |  Time(s) 0.1457 | GPF Loss 1.5355  
Epoch 053 |  Time(s) 0.1480 | GPF Loss 1.5468  
Epoch 054 |  Time(s) 0.1466 | GPF Loss 1.5471  
Epoch 055 |  Time(s) 0.1478 | GPF Loss 1.5309  
Epoch 056 |  Time(s) 0.1462 | GPF Loss 1.5374  
Epoch 057 |  Time(s) 0.1425 | GPF Loss 1.5340  
Epoch 058 |  Time(s) 0.1419 | GPF Loss 1.5283  
Epoch 059 |  Time(s) 0.2086 | GPF Loss 1.5327  
Epoch 060 |  Time(s) 0.1980 | GPF Loss 1.5314  
Epoch 061 |  Time(s) 0.1694 | GPF Loss 1.5237  
Epoch 062 |  Time(s) 0.1545 | GPF Loss 1.5246  
Epoch 063 |  Time(s) 0.1561 | GPF Loss 1.5259  
Epoch 064 |  Time(s) 0.1974 | GPF Loss 1.5326  
Epoch 065 |  Time(s) 0.1507 | GPF Loss 1.5377  
Epoch 066 |  Time(s) 0.1500 | GPF Loss 1.5510  
Epoch 067 |  Time(s) 0.1493 | GPF Loss 1.5266  
Epoch 068 |  Time(s) 0.1450 | GPF Loss 1.5211  
Epoch 069 |  Time(s) 0.1443 | GPF Loss 1.5358  
Epoch 070 |  Time(s) 0.1450 | GPF Loss 1.5488  
Epoch 071 |  Time(s) 0.1453 | GPF Loss 1.5631  
Epoch 072 |  Time(s) 0.1451 | GPF Loss 1.5209  
Epoch 073 |  Time(s) 0.1464 | GPF Loss 1.5993  
Epoch 074 |  Time(s) 0.1452 | GPF Loss 1.5719  
Epoch 075 |  Time(s) 0.1434 | GPF Loss 1.6081  
Epoch 076 |  Time(s) 0.1427 | GPF Loss 1.5657  
Epoch 077 |  Time(s) 0.1435 | GPF Loss 1.5590  
Epoch 078 |  Time(s) 0.1405 | GPF Loss 1.5922  
Epoch 079 |  Time(s) 0.1422 | GPF Loss 1.5921  
Epoch 080 |  Time(s) 0.1398 | GPF Loss 1.5357  
Epoch 081 |  Time(s) 0.1415 | GPF Loss 1.6193  
Epoch 082 |  Time(s) 0.1423 | GPF Loss 1.5417  
Epoch 083 |  Time(s) 0.1450 | GPF Loss 1.5566  
Epoch 084 |  Time(s) 0.1437 | GPF Loss 1.5596  
Epoch 085 |  Time(s) 0.1721 | GPF Loss 1.5418  
Epoch 086 |  Time(s) 0.1635 | GPF Loss 1.5360  
Epoch 087 |  Time(s) 0.1441 | GPF Loss 1.5382  
Epoch 088 |  Time(s) 0.1526 | GPF Loss 1.5267  
Epoch 089 |  Time(s) 0.1544 | GPF Loss 1.5431  
Epoch 090 |  Time(s) 0.1610 | GPF Loss 1.5482  
Epoch 091 |  Time(s) 0.1514 | GPF Loss 1.5212  
----------------------------------------------------------------------------------------------------
Early stopping at 92 eopch!
Batch 0/19 Acc: 0.3500 | Macro-F1: 0.2491
Batch 1/19 Acc: 0.4100 | Macro-F1: 0.3116
Batch 2/19 Acc: 0.3700 | Macro-F1: 0.3028
Batch 3/19 Acc: 0.4100 | Macro-F1: 0.2952
Batch 4/19 Acc: 0.3600 | Macro-F1: 0.2666
Batch 5/19 Acc: 0.2500 | Macro-F1: 0.2122
Batch 6/19 Acc: 0.5200 | Macro-F1: 0.3845
Batch 7/19 Acc: 0.4000 | Macro-F1: 0.2887
Batch 8/19 Acc: 0.3700 | Macro-F1: 0.2631
Batch 9/19 Acc: 0.3400 | Macro-F1: 0.2340
Batch 10/19 Acc: 0.2900 | Macro-F1: 0.2228
Batch 11/19 Acc: 0.3700 | Macro-F1: 0.2699
Batch 12/19 Acc: 0.4300 | Macro-F1: 0.3096
Batch 13/19 Acc: 0.4400 | Macro-F1: 0.3220
Batch 14/19 Acc: 0.4300 | Macro-F1: 0.3280
Batch 15/19 Acc: 0.4300 | Macro-F1: 0.3262
Batch 16/19 Acc: 0.3400 | Macro-F1: 0.2906
Batch 17/19 Acc: 0.4500 | Macro-F1: 0.3259
Batch 18/19 Acc: 0.3556 | Macro-F1: 0.2578
Final True Accuracy: 0.3859 | Macro F1 Score: 0.2958
best_loss [1.5473458766937256]
{1: {1: 0.3859078586101532}}
{1: {1: 0.3859078586101532}}
########################################################################################
seed: 1 | split 1 : 0.3859078586101532
# Seed 1 Muti Split Final Acc: 0.3859±0.0000
########################################################################################
There's only one result, it's recommended to try several seeds.
split: 1 | seed 1 : 0.3859078586101532
# Split 1 Muti Seed Acc without min value: 0.3859±0.0000
########################################################################################
