load LLC or attacked shot data with default split
{'scenario': 'poisoning', 'split': 0, 'adaptive_attack_model': 'grand', 'ptb_rate': 0.1262}
======================
Number of graphs: 1
Number of features: 3703
Number of classes: 6

Data(x=[2110, 3703], edge_index=[2, 10356], y=[2110], train_mask=[2110], val_mask=[2110], test_mask=[2110])
===========================================================================================================
Number of nodes: 2110
Number of edges: 10356
Average node degree: 4.91
Has isolated nodes: False
Has self-loops: True
Is undirected: True
None
tensor([ 603,  822, 1332, 1531, 1997,  106, 1133,  742,  739, 1600,  126,  193,
        1407,  564,  820,  333,  423, 1705,  404, 1220,  282,  670,  121,  830,
        1958, 1916, 1218,   88,  466,   72,  623, 1625, 2050, 1835, 1938, 1393,
        1166, 1375,  767,  993,  660, 1056, 1879,  337, 1230, 1788, 1211, 1465,
        1202,  452, 1523, 1441,  191, 1443, 1183,  636, 1708, 1448, 1739, 2053])
tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,
        4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])
len train nodes: 60
len val   nodes: 205
len test  nodes: 1845
Successfully loaded pre-trained weights!
prepare induce graph data is finished!
run GPF
Epoch 001 |  Time(s) 0.9753 | GPF Loss 1.8498  
Epoch 002 |  Time(s) 0.1448 | GPF Loss 1.7700  
Epoch 003 |  Time(s) 0.1692 | GPF Loss 1.7748  
Epoch 004 |  Time(s) 0.1449 | GPF Loss 1.8220  
Epoch 005 |  Time(s) 0.1451 | GPF Loss 1.7773  
Epoch 006 |  Time(s) 0.1527 | GPF Loss 1.7894  
Epoch 007 |  Time(s) 0.1515 | GPF Loss 1.7908  
Epoch 008 |  Time(s) 0.1455 | GPF Loss 1.7910  
Epoch 009 |  Time(s) 0.1455 | GPF Loss 1.7903  
Epoch 010 |  Time(s) 0.1436 | GPF Loss 1.7776  
Epoch 011 |  Time(s) 0.1447 | GPF Loss 1.8281  
Epoch 012 |  Time(s) 0.1458 | GPF Loss 1.7766  
Epoch 013 |  Time(s) 0.1487 | GPF Loss 1.7860  
Epoch 014 |  Time(s) 0.1465 | GPF Loss 1.7769  
Epoch 015 |  Time(s) 0.1443 | GPF Loss 1.7742  
Epoch 016 |  Time(s) 0.1473 | GPF Loss 1.7986  
Epoch 017 |  Time(s) 0.1481 | GPF Loss 1.7820  
Epoch 018 |  Time(s) 0.1462 | GPF Loss 1.7892  
Epoch 019 |  Time(s) 0.1458 | GPF Loss 1.7800  
Epoch 020 |  Time(s) 0.1484 | GPF Loss 1.7583  
Epoch 021 |  Time(s) 0.1471 | GPF Loss 1.8437  
Epoch 022 |  Time(s) 0.1571 | GPF Loss 1.8540  
Epoch 023 |  Time(s) 0.1688 | GPF Loss 1.8401  
Epoch 024 |  Time(s) 0.1531 | GPF Loss 1.7583  
Epoch 025 |  Time(s) 0.1729 | GPF Loss 1.7725  
Epoch 026 |  Time(s) 0.1891 | GPF Loss 1.7758  
Epoch 027 |  Time(s) 0.1904 | GPF Loss 1.7761  
Epoch 028 |  Time(s) 0.1737 | GPF Loss 1.7802  
Epoch 029 |  Time(s) 0.2783 | GPF Loss 1.7768  
Epoch 030 |  Time(s) 0.1578 | GPF Loss 1.7755  
Epoch 031 |  Time(s) 0.1548 | GPF Loss 1.7741  
Epoch 032 |  Time(s) 0.1562 | GPF Loss 1.7748  
Epoch 033 |  Time(s) 0.1470 | GPF Loss 1.7751  
Epoch 034 |  Time(s) 0.1445 | GPF Loss 1.7743  
Epoch 035 |  Time(s) 0.1360 | GPF Loss 1.7709  
Epoch 036 |  Time(s) 0.1521 | GPF Loss 1.7591  
Epoch 037 |  Time(s) 0.1511 | GPF Loss 1.7570  
Epoch 038 |  Time(s) 0.1758 | GPF Loss 1.7398  
Epoch 039 |  Time(s) 0.1594 | GPF Loss 1.7123  
Epoch 040 |  Time(s) 0.1610 | GPF Loss 1.7345  
Epoch 041 |  Time(s) 0.1610 | GPF Loss 1.7350  
Epoch 042 |  Time(s) 0.1619 | GPF Loss 1.6278  
Epoch 043 |  Time(s) 0.1436 | GPF Loss 1.7020  
Epoch 044 |  Time(s) 0.1445 | GPF Loss 1.6579  
Epoch 045 |  Time(s) 0.1438 | GPF Loss 1.6819  
Epoch 046 |  Time(s) 0.1440 | GPF Loss 1.6458  
Epoch 047 |  Time(s) 0.1441 | GPF Loss 1.6159  
Epoch 048 |  Time(s) 0.1424 | GPF Loss 1.6888  
Epoch 049 |  Time(s) 0.1487 | GPF Loss 1.6027  
Epoch 050 |  Time(s) 0.1434 | GPF Loss 1.6300  
Epoch 051 |  Time(s) 0.1439 | GPF Loss 1.6148  
Epoch 052 |  Time(s) 0.1442 | GPF Loss 1.6429  
Epoch 053 |  Time(s) 0.1437 | GPF Loss 1.6552  
Epoch 054 |  Time(s) 0.1439 | GPF Loss 1.6209  
Epoch 055 |  Time(s) 0.1441 | GPF Loss 1.6086  
Epoch 056 |  Time(s) 0.1486 | GPF Loss 1.6065  
Epoch 057 |  Time(s) 0.1432 | GPF Loss 1.6110  
Epoch 058 |  Time(s) 0.1884 | GPF Loss 1.6312  
Epoch 059 |  Time(s) 0.2120 | GPF Loss 1.6178  
Epoch 060 |  Time(s) 0.1660 | GPF Loss 1.6081  
Epoch 061 |  Time(s) 0.1534 | GPF Loss 1.6093  
Epoch 062 |  Time(s) 0.1442 | GPF Loss 1.6099  
Epoch 063 |  Time(s) 0.1478 | GPF Loss 1.6157  
Epoch 064 |  Time(s) 0.1470 | GPF Loss 1.6245  
Epoch 065 |  Time(s) 0.1548 | GPF Loss 1.6133  
Epoch 066 |  Time(s) 0.1476 | GPF Loss 1.6097  
Epoch 067 |  Time(s) 0.1505 | GPF Loss 1.6105  
Epoch 068 |  Time(s) 0.1523 | GPF Loss 1.6087  
----------------------------------------------------------------------------------------------------
Early stopping at 69 eopch!
Batch 0/19 Acc: 0.4300 | Macro-F1: 0.2470
Batch 1/19 Acc: 0.4300 | Macro-F1: 0.2525
Batch 2/19 Acc: 0.2900 | Macro-F1: 0.1824
Batch 3/19 Acc: 0.4200 | Macro-F1: 0.2721
Batch 4/19 Acc: 0.3500 | Macro-F1: 0.2217
Batch 5/19 Acc: 0.3200 | Macro-F1: 0.2019
Batch 6/19 Acc: 0.4000 | Macro-F1: 0.2368
Batch 7/19 Acc: 0.4600 | Macro-F1: 0.2772
Batch 8/19 Acc: 0.3700 | Macro-F1: 0.2279
Batch 9/19 Acc: 0.3200 | Macro-F1: 0.2103
Batch 10/19 Acc: 0.3600 | Macro-F1: 0.2368
Batch 11/19 Acc: 0.3800 | Macro-F1: 0.2150
Batch 12/19 Acc: 0.3600 | Macro-F1: 0.2257
Batch 13/19 Acc: 0.4000 | Macro-F1: 0.2558
Batch 14/19 Acc: 0.3300 | Macro-F1: 0.1884
Batch 15/19 Acc: 0.4200 | Macro-F1: 0.2463
Batch 16/19 Acc: 0.2500 | Macro-F1: 0.1680
Batch 17/19 Acc: 0.4600 | Macro-F1: 0.2642
Batch 18/19 Acc: 0.4889 | Macro-F1: 0.3072
Final True Accuracy: 0.3778 | Macro F1 Score: 0.2356
best_loss [1.608087420463562]
{1: {1: 0.3777777850627899}}
{1: {1: 0.3777777850627899}}
########################################################################################
seed: 1 | split 1 : 0.3777777850627899
# Seed 1 Muti Split Final Acc: 0.3778±0.0000
########################################################################################
There's only one result, it's recommended to try several seeds.
split: 1 | seed 1 : 0.3777777850627899
# Split 1 Muti Seed Acc without min value: 0.3778±0.0000
########################################################################################
