load LLC or attacked shot data with default split
{'scenario': 'poisoning', 'split': 0, 'adaptive_attack_model': 'jaccard_gcn', 'ptb_rate': 0.1499}
======================
Number of graphs: 1
Number of features: 3703
Number of classes: 6

Data(x=[2110, 3703], edge_index=[2, 10546], y=[2110], train_mask=[2110], val_mask=[2110], test_mask=[2110])
===========================================================================================================
Number of nodes: 2110
Number of edges: 10546
Average node degree: 5.00
Has isolated nodes: False
Has self-loops: True
Is undirected: True
None
tensor([ 603,  822, 1332, 1531, 1997,  106, 1133,  742,  739, 1600,  126,  193,
        1407,  564,  820,  333,  423, 1705,  404, 1220,  282,  670,  121,  830,
        1958, 1916, 1218,   88,  466,   72,  623, 1625, 2050, 1835, 1938, 1393,
        1166, 1375,  767,  993,  660, 1056, 1879,  337, 1230, 1788, 1211, 1465,
        1202,  452, 1523, 1441,  191, 1443, 1183,  636, 1708, 1448, 1739, 2053])
tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,
        4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])
len train nodes: 60
len val   nodes: 205
len test  nodes: 1845
adj torch.Size([2110, 2110])
feature (2110, 3703)
Citeseer
Now use adaptive clean for pretrain !
#############
start sampling disconnected tuples
run MultiGprompt
Epoch 001 |  Time(s) 1.2625 | MultiGprompt Loss 1.7911  
Epoch 002 |  Time(s) 0.2290 | MultiGprompt Loss 1.7911  
Epoch 003 |  Time(s) 0.2934 | MultiGprompt Loss 1.7911  
Epoch 004 |  Time(s) 0.3087 | MultiGprompt Loss 1.7911  
Epoch 005 |  Time(s) 0.3346 | MultiGprompt Loss 1.7911  
Epoch 006 |  Time(s) 0.3481 | MultiGprompt Loss 1.7911  
Epoch 007 |  Time(s) 0.3309 | MultiGprompt Loss 1.7911  
Epoch 008 |  Time(s) 0.3365 | MultiGprompt Loss 1.7911  
Epoch 009 |  Time(s) 0.3388 | MultiGprompt Loss 1.7911  
Epoch 010 |  Time(s) 0.3545 | MultiGprompt Loss 1.7911  
Epoch 011 |  Time(s) 0.3374 | MultiGprompt Loss 1.7911  
Epoch 012 |  Time(s) 0.3361 | MultiGprompt Loss 1.7911  
Epoch 013 |  Time(s) 0.3313 | MultiGprompt Loss 1.7911  
Epoch 014 |  Time(s) 0.3035 | MultiGprompt Loss 1.7911  
Epoch 015 |  Time(s) 0.3376 | MultiGprompt Loss 1.7911  
Epoch 016 |  Time(s) 0.3302 | MultiGprompt Loss 1.7910  
Epoch 017 |  Time(s) 0.3336 | MultiGprompt Loss 1.7910  
Epoch 018 |  Time(s) 0.3350 | MultiGprompt Loss 1.7910  
Epoch 019 |  Time(s) 0.3299 | MultiGprompt Loss 1.7910  
Epoch 020 |  Time(s) 0.3269 | MultiGprompt Loss 1.7910  
Epoch 021 |  Time(s) 0.3455 | MultiGprompt Loss 1.7910  
Epoch 022 |  Time(s) 0.3354 | MultiGprompt Loss 1.7910  
Epoch 023 |  Time(s) 0.3393 | MultiGprompt Loss 1.7910  
Epoch 024 |  Time(s) 0.3349 | MultiGprompt Loss 1.7910  
Epoch 025 |  Time(s) 0.3376 | MultiGprompt Loss 1.7910  
Epoch 026 |  Time(s) 0.3316 | MultiGprompt Loss 1.7910  
Epoch 027 |  Time(s) 0.3394 | MultiGprompt Loss 1.7910  
Epoch 028 |  Time(s) 0.3406 | MultiGprompt Loss 1.7909  
Epoch 029 |  Time(s) 0.3369 | MultiGprompt Loss 1.7909  
Epoch 030 |  Time(s) 0.3476 | MultiGprompt Loss 1.7909  
Epoch 031 |  Time(s) 0.3372 | MultiGprompt Loss 1.7909  
Epoch 032 |  Time(s) 0.3370 | MultiGprompt Loss 1.7909  
Epoch 033 |  Time(s) 0.3492 | MultiGprompt Loss 1.7909  
Epoch 034 |  Time(s) 0.3455 | MultiGprompt Loss 1.7909  
Epoch 035 |  Time(s) 0.3466 | MultiGprompt Loss 1.7909  
Epoch 036 |  Time(s) 0.3421 | MultiGprompt Loss 1.7909  
Epoch 037 |  Time(s) 0.3409 | MultiGprompt Loss 1.7909  
Epoch 038 |  Time(s) 0.3434 | MultiGprompt Loss 1.7908  
Epoch 039 |  Time(s) 0.3452 | MultiGprompt Loss 1.7908  
Epoch 040 |  Time(s) 0.3386 | MultiGprompt Loss 1.7908  
Epoch 041 |  Time(s) 0.3436 | MultiGprompt Loss 1.7908  
Epoch 042 |  Time(s) 0.3362 | MultiGprompt Loss 1.7908  
Epoch 043 |  Time(s) 0.3419 | MultiGprompt Loss 1.7908  
Epoch 044 |  Time(s) 0.3481 | MultiGprompt Loss 1.7908  
Epoch 045 |  Time(s) 0.3440 | MultiGprompt Loss 1.7908  
Epoch 046 |  Time(s) 0.3278 | MultiGprompt Loss 1.7907  
Epoch 047 |  Time(s) 0.3577 | MultiGprompt Loss 1.7907  
Epoch 048 |  Time(s) 0.3386 | MultiGprompt Loss 1.7907  
Epoch 049 |  Time(s) 0.3433 | MultiGprompt Loss 1.7907  
Epoch 050 |  Time(s) 0.3419 | MultiGprompt Loss 1.7907  
Epoch 051 |  Time(s) 0.3034 | MultiGprompt Loss 1.7907  
Epoch 052 |  Time(s) 0.3511 | MultiGprompt Loss 1.7907  
Epoch 053 |  Time(s) 0.3474 | MultiGprompt Loss 1.7906  
Epoch 054 |  Time(s) 0.3067 | MultiGprompt Loss 1.7906  
Epoch 055 |  Time(s) 0.3303 | MultiGprompt Loss 1.7906  
Epoch 056 |  Time(s) 0.3437 | MultiGprompt Loss 1.7906  
Epoch 057 |  Time(s) 0.3470 | MultiGprompt Loss 1.7906  
Epoch 058 |  Time(s) 0.3548 | MultiGprompt Loss 1.7906  
Epoch 059 |  Time(s) 0.3375 | MultiGprompt Loss 1.7905  
Epoch 060 |  Time(s) 0.3394 | MultiGprompt Loss 1.7905  
Epoch 061 |  Time(s) 0.3368 | MultiGprompt Loss 1.7905  
Epoch 062 |  Time(s) 0.3348 | MultiGprompt Loss 1.7905  
Epoch 063 |  Time(s) 0.3253 | MultiGprompt Loss 1.7905  
Epoch 064 |  Time(s) 0.3403 | MultiGprompt Loss 1.7905  
Epoch 065 |  Time(s) 0.3423 | MultiGprompt Loss 1.7904  
Epoch 066 |  Time(s) 0.3330 | MultiGprompt Loss 1.7904  
Epoch 067 |  Time(s) 0.3419 | MultiGprompt Loss 1.7904  
Epoch 068 |  Time(s) 0.3334 | MultiGprompt Loss 1.7904  
Epoch 069 |  Time(s) 0.3048 | MultiGprompt Loss 1.7904  
Epoch 070 |  Time(s) 0.3448 | MultiGprompt Loss 1.7903  
Epoch 071 |  Time(s) 0.3381 | MultiGprompt Loss 1.7903  
Epoch 072 |  Time(s) 0.3267 | MultiGprompt Loss 1.7903  
Epoch 073 |  Time(s) 0.3485 | MultiGprompt Loss 1.7903  
Epoch 074 |  Time(s) 0.3410 | MultiGprompt Loss 1.7903  
Epoch 075 |  Time(s) 0.3273 | MultiGprompt Loss 1.7902  
Epoch 076 |  Time(s) 0.3431 | MultiGprompt Loss 1.7902  
Epoch 077 |  Time(s) 0.3366 | MultiGprompt Loss 1.7902  
Epoch 078 |  Time(s) 0.3225 | MultiGprompt Loss 1.7902  
Epoch 079 |  Time(s) 0.3530 | MultiGprompt Loss 1.7901  
Epoch 080 |  Time(s) 0.3343 | MultiGprompt Loss 1.7901  
Epoch 081 |  Time(s) 0.3171 | MultiGprompt Loss 1.7901  
Epoch 082 |  Time(s) 0.3366 | MultiGprompt Loss 1.7901  
Epoch 083 |  Time(s) 0.3472 | MultiGprompt Loss 1.7901  
Epoch 084 |  Time(s) 0.3483 | MultiGprompt Loss 1.7900  
Epoch 085 |  Time(s) 0.3422 | MultiGprompt Loss 1.7900  
Epoch 086 |  Time(s) 0.3410 | MultiGprompt Loss 1.7900  
Epoch 087 |  Time(s) 0.3081 | MultiGprompt Loss 1.7900  
Epoch 088 |  Time(s) 0.3431 | MultiGprompt Loss 1.7899  
Epoch 089 |  Time(s) 0.3507 | MultiGprompt Loss 1.7899  
Epoch 090 |  Time(s) 0.3473 | MultiGprompt Loss 1.7899  
Epoch 091 |  Time(s) 0.3370 | MultiGprompt Loss 1.7899  
Epoch 092 |  Time(s) 0.3411 | MultiGprompt Loss 1.7898  
Epoch 093 |  Time(s) 0.3397 | MultiGprompt Loss 1.7898  
Epoch 094 |  Time(s) 0.3290 | MultiGprompt Loss 1.7898  
Epoch 095 |  Time(s) 0.3359 | MultiGprompt Loss 1.7898  
Epoch 096 |  Time(s) 0.3382 | MultiGprompt Loss 1.7897  
Epoch 097 |  Time(s) 0.3496 | MultiGprompt Loss 1.7897  
Epoch 098 |  Time(s) 0.3471 | MultiGprompt Loss 1.7897  
Epoch 099 |  Time(s) 0.3278 | MultiGprompt Loss 1.7897  
Epoch 100 |  Time(s) 0.3471 | MultiGprompt Loss 1.7896  
Final True Accuracy: 0.3339 | Macro F1 Score: 0.3032
best_loss [1.7896238565444946]
{1: {1: 0.3338753283023834}}
{1: {1: 0.3338753283023834}}
########################################################################################
seed: 1 | split 1 : 0.3338753283023834
# Seed 1 Muti Split Final Acc: 0.3339±0.0000
########################################################################################
There's only one result, it's recommended to try several seeds.
split: 1 | seed 1 : 0.3338753283023834
# Split 1 Muti Seed Acc without min value: 0.3339±0.0000
########################################################################################
