load LLC or attacked shot data with default split
{'scenario': 'poisoning', 'split': 0, 'adaptive_attack_model': 'svd_gcn', 'ptb_rate': 0.1274}
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7

Data(x=[2485, 1433], edge_index=[2, 13915], y=[2485], train_mask=[2485], val_mask=[2485], test_mask=[2485])
===========================================================================================================
Number of nodes: 2485
Number of edges: 13915
Average node degree: 5.60
Has isolated nodes: False
Has self-loops: True
Is undirected: True
None
tensor([1756,  307,   33, 1404,  188,  392, 2426,  422, 1970, 1832, 2052,  775,
         774, 2081, 1717, 1530, 1793, 1991, 2055, 1901, 2068,  689,  254, 1280,
         225,  252, 1493, 1286,  849, 1975,  870, 2131, 1445, 1204, 1459, 1695,
         432, 1570, 1701, 2093, 1394, 1120,  728, 1165, 1540,  934, 2001,  428,
        1058, 1297, 2302, 1798,  937, 1929, 1764, 2155, 1979, 1085, 1866,  145,
        1142, 2143, 1830,  532,  803, 2058, 1461, 1358, 1672,  682])
tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,
        4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6])
len train nodes: 70
len val   nodes: 241
len test  nodes: 2174
adj torch.Size([2485, 2485])
feature (2485, 1433)
Cora_ml
Now use adaptive clean for pretrain !
#############
start sampling disconnected tuples
run MultiGprompt
Epoch 001 |  Time(s) 1.2524 | MultiGprompt Loss 1.9348  
Epoch 002 |  Time(s) 0.3470 | MultiGprompt Loss 1.9343  
Epoch 003 |  Time(s) 0.3805 | MultiGprompt Loss 1.9337  
Epoch 004 |  Time(s) 0.3873 | MultiGprompt Loss 1.9331  
Epoch 005 |  Time(s) 0.4110 | MultiGprompt Loss 1.9325  
Epoch 006 |  Time(s) 0.4671 | MultiGprompt Loss 1.9319  
Epoch 007 |  Time(s) 0.4927 | MultiGprompt Loss 1.9313  
Epoch 008 |  Time(s) 0.5058 | MultiGprompt Loss 1.9307  
Epoch 009 |  Time(s) 0.5216 | MultiGprompt Loss 1.9300  
Epoch 010 |  Time(s) 0.4899 | MultiGprompt Loss 1.9293  
Epoch 011 |  Time(s) 0.5014 | MultiGprompt Loss 1.9287  
Epoch 012 |  Time(s) 0.4977 | MultiGprompt Loss 1.9280  
Epoch 013 |  Time(s) 0.5049 | MultiGprompt Loss 1.9274  
Epoch 014 |  Time(s) 0.5160 | MultiGprompt Loss 1.9267  
Epoch 015 |  Time(s) 0.4906 | MultiGprompt Loss 1.9261  
Epoch 016 |  Time(s) 0.4934 | MultiGprompt Loss 1.9254  
Epoch 017 |  Time(s) 0.4959 | MultiGprompt Loss 1.9248  
Epoch 018 |  Time(s) 0.5006 | MultiGprompt Loss 1.9240  
Epoch 019 |  Time(s) 0.4983 | MultiGprompt Loss 1.9238  
Epoch 020 |  Time(s) 0.4939 | MultiGprompt Loss 1.9231  
Epoch 021 |  Time(s) 0.4983 | MultiGprompt Loss 1.9227  
Epoch 022 |  Time(s) 0.4879 | MultiGprompt Loss 1.9224  
Epoch 023 |  Time(s) 0.4965 | MultiGprompt Loss 1.9217  
Epoch 024 |  Time(s) 0.4922 | MultiGprompt Loss 1.9212  
Epoch 025 |  Time(s) 0.5063 | MultiGprompt Loss 1.9210  
Epoch 026 |  Time(s) 0.4997 | MultiGprompt Loss 1.9209  
Epoch 027 |  Time(s) 0.5022 | MultiGprompt Loss 1.9210  
Epoch 028 |  Time(s) 0.5048 | MultiGprompt Loss 1.9209  
Epoch 029 |  Time(s) 0.4963 | MultiGprompt Loss 1.9209  
Epoch 030 |  Time(s) 0.4963 | MultiGprompt Loss 1.9208  
Epoch 031 |  Time(s) 0.4923 | MultiGprompt Loss 1.9205  
Epoch 032 |  Time(s) 0.5017 | MultiGprompt Loss 1.9202  
Epoch 033 |  Time(s) 0.4895 | MultiGprompt Loss 1.9199  
Epoch 034 |  Time(s) 0.5009 | MultiGprompt Loss 1.9197  
Epoch 035 |  Time(s) 0.4941 | MultiGprompt Loss 1.9195  
Epoch 036 |  Time(s) 0.5053 | MultiGprompt Loss 1.9194  
Epoch 037 |  Time(s) 0.4902 | MultiGprompt Loss 1.9192  
Epoch 038 |  Time(s) 0.4976 | MultiGprompt Loss 1.9191  
Epoch 039 |  Time(s) 0.4959 | MultiGprompt Loss 1.9190  
Epoch 040 |  Time(s) 0.5026 | MultiGprompt Loss 1.9188  
Epoch 041 |  Time(s) 0.5081 | MultiGprompt Loss 1.9186  
Epoch 042 |  Time(s) 0.5206 | MultiGprompt Loss 1.9184  
Epoch 043 |  Time(s) 0.4365 | MultiGprompt Loss 1.9182  
Epoch 044 |  Time(s) 0.4106 | MultiGprompt Loss 1.9181  
Epoch 045 |  Time(s) 0.3836 | MultiGprompt Loss 1.9181  
Epoch 046 |  Time(s) 0.3876 | MultiGprompt Loss 1.9181  
Epoch 047 |  Time(s) 0.3838 | MultiGprompt Loss 1.9179  
Epoch 048 |  Time(s) 0.4110 | MultiGprompt Loss 1.9178  
Epoch 049 |  Time(s) 0.4093 | MultiGprompt Loss 1.9177  
Epoch 050 |  Time(s) 0.3927 | MultiGprompt Loss 1.9176  
Epoch 051 |  Time(s) 0.4944 | MultiGprompt Loss 1.9178  
Epoch 052 |  Time(s) 0.4998 | MultiGprompt Loss 1.9181  
Epoch 053 |  Time(s) 0.4889 | MultiGprompt Loss 1.9181  
Epoch 054 |  Time(s) 0.4989 | MultiGprompt Loss 1.9198  
Epoch 055 |  Time(s) 0.4880 | MultiGprompt Loss 1.9200  
Epoch 056 |  Time(s) 0.4888 | MultiGprompt Loss 1.9195  
Epoch 057 |  Time(s) 0.4901 | MultiGprompt Loss 1.9193  
Epoch 058 |  Time(s) 0.5085 | MultiGprompt Loss 1.9194  
Epoch 059 |  Time(s) 0.4903 | MultiGprompt Loss 1.9196  
Epoch 060 |  Time(s) 0.4944 | MultiGprompt Loss 1.9197  
Epoch 061 |  Time(s) 0.4906 | MultiGprompt Loss 1.9198  
Epoch 062 |  Time(s) 0.4955 | MultiGprompt Loss 1.9198  
Epoch 063 |  Time(s) 0.4903 | MultiGprompt Loss 1.9198  
Epoch 064 |  Time(s) 0.4921 | MultiGprompt Loss 1.9198  
Epoch 065 |  Time(s) 0.4934 | MultiGprompt Loss 1.9198  
Epoch 066 |  Time(s) 0.4906 | MultiGprompt Loss 1.9197  
Epoch 067 |  Time(s) 0.4896 | MultiGprompt Loss 1.9197  
Epoch 068 |  Time(s) 0.4968 | MultiGprompt Loss 1.9196  
Epoch 069 |  Time(s) 0.5026 | MultiGprompt Loss 1.9195  
----------------------------------------------------------------------------------------------------
Early stopping at 70 eopch!
Final True Accuracy: 0.2999 | Macro F1 Score: 0.2069
best_loss [1.9194265604019165]
{1: {1: 0.29990801215171814}}
{1: {1: 0.29990801215171814}}
########################################################################################
seed: 1 | split 1 : 0.29990801215171814
# Seed 1 Muti Split Final Acc: 0.2999±0.0000
########################################################################################
There's only one result, it's recommended to try several seeds.
split: 1 | seed 1 : 0.29990801215171814
# Split 1 Muti Seed Acc without min value: 0.2999±0.0000
########################################################################################
