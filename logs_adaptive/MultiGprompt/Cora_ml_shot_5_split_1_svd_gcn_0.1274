load LLC or attacked shot data with default split
{'scenario': 'poisoning', 'split': 0, 'adaptive_attack_model': 'svd_gcn', 'ptb_rate': 0.1274}
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7

Data(x=[2485, 1433], edge_index=[2, 13915], y=[2485], train_mask=[2485], val_mask=[2485], test_mask=[2485])
===========================================================================================================
Number of nodes: 2485
Number of edges: 13915
Average node degree: 5.60
Has isolated nodes: False
Has self-loops: True
Is undirected: True
None
tensor([1756,  307,   33, 1404,  188, 2052,  775,  774, 2081, 1717, 2068,  689,
         254, 1280,  225,  870, 2131, 1445, 1204, 1459, 1394, 1120,  728, 1165,
        1540, 2302, 1798,  937, 1929, 1764, 1142, 2143, 1830,  532,  803])
tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4,
        4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6])
len train nodes: 35
len val   nodes: 245
len test  nodes: 2205
adj torch.Size([2485, 2485])
feature (2485, 1433)
Cora_ml
Now use adaptive clean for pretrain !
#############
start sampling disconnected tuples
run MultiGprompt
Epoch 001 |  Time(s) 1.2184 | MultiGprompt Loss 1.9239  
Epoch 002 |  Time(s) 0.1723 | MultiGprompt Loss 1.9228  
Epoch 003 |  Time(s) 0.2367 | MultiGprompt Loss 1.9218  
Epoch 004 |  Time(s) 0.2559 | MultiGprompt Loss 1.9209  
Epoch 005 |  Time(s) 0.2396 | MultiGprompt Loss 1.9199  
Epoch 006 |  Time(s) 0.2562 | MultiGprompt Loss 1.9190  
Epoch 007 |  Time(s) 0.2648 | MultiGprompt Loss 1.9181  
Epoch 008 |  Time(s) 0.2195 | MultiGprompt Loss 1.9173  
Epoch 009 |  Time(s) 0.2604 | MultiGprompt Loss 1.9165  
Epoch 010 |  Time(s) 0.2575 | MultiGprompt Loss 1.9158  
Epoch 011 |  Time(s) 0.2600 | MultiGprompt Loss 1.9151  
Epoch 012 |  Time(s) 0.2572 | MultiGprompt Loss 1.9144  
Epoch 013 |  Time(s) 0.2516 | MultiGprompt Loss 1.9139  
Epoch 014 |  Time(s) 0.2589 | MultiGprompt Loss 1.9133  
Epoch 015 |  Time(s) 0.2612 | MultiGprompt Loss 1.9129  
Epoch 016 |  Time(s) 0.2586 | MultiGprompt Loss 1.9125  
Epoch 017 |  Time(s) 0.2559 | MultiGprompt Loss 1.9121  
Epoch 018 |  Time(s) 0.2599 | MultiGprompt Loss 1.9117  
Epoch 019 |  Time(s) 0.2567 | MultiGprompt Loss 1.9114  
Epoch 020 |  Time(s) 0.2528 | MultiGprompt Loss 1.9111  
Epoch 021 |  Time(s) 0.2567 | MultiGprompt Loss 1.9108  
Epoch 022 |  Time(s) 0.2565 | MultiGprompt Loss 1.9105  
Epoch 023 |  Time(s) 0.2542 | MultiGprompt Loss 1.9102  
Epoch 024 |  Time(s) 0.2564 | MultiGprompt Loss 1.9099  
Epoch 025 |  Time(s) 0.2469 | MultiGprompt Loss 1.9097  
Epoch 026 |  Time(s) 0.2579 | MultiGprompt Loss 1.9094  
Epoch 027 |  Time(s) 0.2583 | MultiGprompt Loss 1.9092  
Epoch 028 |  Time(s) 0.2502 | MultiGprompt Loss 1.9090  
Epoch 029 |  Time(s) 0.2158 | MultiGprompt Loss 1.9087  
Epoch 030 |  Time(s) 0.2137 | MultiGprompt Loss 1.9085  
Epoch 031 |  Time(s) 0.2509 | MultiGprompt Loss 1.9084  
Epoch 032 |  Time(s) 0.2213 | MultiGprompt Loss 1.9082  
Epoch 033 |  Time(s) 0.2641 | MultiGprompt Loss 1.9080  
Epoch 034 |  Time(s) 0.2562 | MultiGprompt Loss 1.9079  
Epoch 035 |  Time(s) 0.2560 | MultiGprompt Loss 1.9077  
Epoch 036 |  Time(s) 0.2563 | MultiGprompt Loss 1.9074  
Epoch 037 |  Time(s) 0.2551 | MultiGprompt Loss 1.9072  
Epoch 038 |  Time(s) 0.2203 | MultiGprompt Loss 1.9069  
Epoch 039 |  Time(s) 0.2555 | MultiGprompt Loss 1.9067  
Epoch 040 |  Time(s) 0.2622 | MultiGprompt Loss 1.9065  
Epoch 041 |  Time(s) 0.2559 | MultiGprompt Loss 1.9063  
Epoch 042 |  Time(s) 0.2143 | MultiGprompt Loss 1.9059  
Epoch 043 |  Time(s) 0.2520 | MultiGprompt Loss 1.9056  
Epoch 044 |  Time(s) 0.2506 | MultiGprompt Loss 1.9052  
Epoch 045 |  Time(s) 0.2137 | MultiGprompt Loss 1.9049  
Epoch 046 |  Time(s) 0.2610 | MultiGprompt Loss 1.9047  
Epoch 047 |  Time(s) 0.2546 | MultiGprompt Loss 1.9044  
Epoch 048 |  Time(s) 0.2330 | MultiGprompt Loss 1.9042  
Epoch 049 |  Time(s) 0.2125 | MultiGprompt Loss 1.9040  
Epoch 050 |  Time(s) 0.2562 | MultiGprompt Loss 1.9037  
Epoch 051 |  Time(s) 0.2627 | MultiGprompt Loss 1.9051  
Epoch 052 |  Time(s) 0.2623 | MultiGprompt Loss 1.9073  
Epoch 053 |  Time(s) 0.2559 | MultiGprompt Loss 1.9078  
Epoch 054 |  Time(s) 0.2611 | MultiGprompt Loss 1.9076  
Epoch 055 |  Time(s) 0.2506 | MultiGprompt Loss 1.9074  
Epoch 056 |  Time(s) 0.2577 | MultiGprompt Loss 1.9072  
Epoch 057 |  Time(s) 0.2512 | MultiGprompt Loss 1.9070  
Epoch 058 |  Time(s) 0.2561 | MultiGprompt Loss 1.9069  
Epoch 059 |  Time(s) 0.2274 | MultiGprompt Loss 1.9068  
Epoch 060 |  Time(s) 0.2585 | MultiGprompt Loss 1.9067  
Epoch 061 |  Time(s) 0.2514 | MultiGprompt Loss 1.9066  
Epoch 062 |  Time(s) 0.2570 | MultiGprompt Loss 1.9065  
Epoch 063 |  Time(s) 0.2564 | MultiGprompt Loss 1.9064  
Epoch 064 |  Time(s) 0.2569 | MultiGprompt Loss 1.9063  
Epoch 065 |  Time(s) 0.2567 | MultiGprompt Loss 1.9062  
Epoch 066 |  Time(s) 0.2662 | MultiGprompt Loss 1.9061  
Epoch 067 |  Time(s) 0.2617 | MultiGprompt Loss 1.9059  
Epoch 068 |  Time(s) 0.2613 | MultiGprompt Loss 1.9058  
Epoch 069 |  Time(s) 0.2608 | MultiGprompt Loss 1.9056  
----------------------------------------------------------------------------------------------------
Early stopping at 70 eopch!
Final True Accuracy: 0.2422 | Macro F1 Score: 0.2176
best_loss [1.905490517616272]
{1: {1: 0.2421768754720688}}
{1: {1: 0.2421768754720688}}
########################################################################################
seed: 1 | split 1 : 0.2421768754720688
# Seed 1 Muti Split Final Acc: 0.2422±0.0000
########################################################################################
There's only one result, it's recommended to try several seeds.
split: 1 | seed 1 : 0.2421768754720688
# Split 1 Muti Seed Acc without min value: 0.2422±0.0000
########################################################################################
